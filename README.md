# Text-Guided Object Labeling in Videos using YOLO and CLIP

This project uses YOLOv8 and OpenAI's CLIP model to perform text-based object labeling in videos.

## Features
- YOLOv8 for object detection
- CLIP for vision-language understanding
- Video annotation with labels from prompts

## Requirements
- PyTorch
- OpenCV
- ultralytics
- git-lfs (for large notebooks)

## Getting Started
1. Clone the repo
2. Install dependencies
3. Run `object_tracking.ipynb`

Download the file
'https://drive.google.com/file/d/1ZXmA_DubeeDo2EELG3g7lzrwh9lhADPm/view?usp=drive_link'
